# Adaptive Learning with Tutor-GPT: Customizing Large Language Models for Educational Purposes

## Introduction

This project focuses on the development and fine-tuning of Large Language Models (LLMs) to act as dynamic tutors in educational settings. Leveraging models like GPT-3, Gemini, and others, we customize these LLMs to enhance learning experiences by providing tailored guidance and support within the academic domains, particularly using resources from the ATU library.

## Background

Transformers and LLMs have revolutionized various aspects of natural language processing. These models are now being extended to educational contexts, where they can function as intelligent tutors. This project seeks to fine-tune such models on domain-specific datasets to help students understand computing literature more effectively.

## Objectives

- **Understand Learning Materials**: Provide clear explanations and insights into computing literature.
- **Generate Questions**: Develop the model's ability to construct questions that help analyze students' understanding.
- **Rectify Misunderstandings**: Address and correct misconceptions students might hold.

## Methodology

### Data Collection
- Gather educational materials related to computing from the ATU library, available in PDF/EPUB formats.

### Preprocessing
- Convert PDF/EPUB files into text and preprocess the data to prepare it for model training.

### Model Selection and Fine-Tuning
- Choose an appropriate pre-trained model (like GPT-2, GPT-3, or Gemini) and fine-tune it on the processed text data specific to computing literature.

### Development of Interactive Features
- Implement functionalities such as on-demand question generation, real-time doubt clarification, and adaptive learning paths based on user interaction.

### Testing and Evaluation
- Employ both quantitative (e.g., quiz scores, completion rates) and qualitative (e.g., student satisfaction, ease of understanding) metrics to evaluate the model's performance.

## Usage

Instructions on how to interact with the model, set up the environment, and any other relevant usage information will be provided here.



## License

Specify the license under which the project is released.

## Contact

For further information, feel free to contact Rajesh Goldy at goldirana3210@gmail.com.

## Acknowledgements

Special thanks to all contributors and researchers who have provided insights and feedback throughout the development of this project.
